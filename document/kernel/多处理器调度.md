## 多处理器调度

| author | update |
| ------ | ------ |
| perrynzhou@gmail.com | 2020/11/13 |

- 多处理器时将多个CPU核组装在一块芯片上,这种多核架构变得很流行,但是也带来了困难，主要的困难是典型的应用程序都使用一个CPU，增加了更多CPU并没有让这类程序运行的更快。为了解决这个问题，必须重新这些应用程序，使之能并行执行，使用多线程。
- 单核和多核CPU主要区别的核心在于对于硬件缓存的使用、以及使用多处理器之间的数据共享的方式。
- 单CPU系统中，存在多级硬件缓存，一般来说会让处理器更快的执行程序。缓存小但是比内存访问要快。程序第一次读取数据时，数据在内存中，内存访问在数十或者数百纳秒，处理器很有可能再次访问这些数据，因此将这些数据存储在硬件缓存中。如果之后在访问这些同样的数据，CPU先会查找缓存读取数据，这个访问时间在几纳秒。
- 缓存是基于局部行的概念，一般会有时间局部性和空间局部性；时间局部性是当一个数据被访问后，很有可能在不就的将来再次访问这个数据，比如循环代码或者指令本身；空间局部性是当程序访问地址X的数据时候，很有可能紧接着访问X周围的数据，比如遍历数组或者指令的顺序执行。
- 多CPU会面临每个CPU的缓存数据不一致的问题，基于这个问题的硬件提供了基本解决方案，通过监控内存访问，硬件可以保证获得正确的数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式是使用总线窥探。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU发现对它放在缓存中的数据更新，CPU会作废自己缓存中的副本数据，然后更新新的副本数据。
- 虽然硬件保证了缓存的一致性，但是应用程序依然需要关心共享数据的访问，跨CPU访问共享数据或者数据结构时候，需要使用互斥原语，才能保证正确性。比如下面代码序列，用于删除一个链表的元素，如果不使用加锁方式，多个线程尝试同时删除同一个链表头，会导致不可预期的结果

	```
	typedef struct node_t {
		int value;
		struct node_t *next;
	}node;
	int main() {
		node *tmp = head;
		int value = head->value;
		head = head->next;
		free(tmp);
	}
	```
- 在设计多处理器调度时候遇到最后一个问题就是缓存亲和性。一个进程在某个CPU上运行，会在该CPU的缓存中维护许多状态。下次改进程在相同CPU上运行时候，由于缓存中已经存在该进程的数据而执行的更快。相反，在不同的CPU上执行，会由于需要重新加载而很慢，因此多处理器调度应该开了这种缓存亲和，尽可能将进程保持在同一个CPU上。
- 单队列调度，所有的需要调度的进程放到同一个大队列中，这样比较简单但是引入了如下问题
	- 扩展性问题:当并发添加一个或者多个进度到调度系统中队列时候，为了保证在多CPU上正常运行，调度程序的开发者需要在代码中加锁保证原子性访问。
	- 缓存亲和性:每个任务的再同一个CPU上运行和CPU上调度的负载均衡不能同时满足。

- 多队列调度，每个CPU都有自己的调度队列，这样的方式减少锁带来的性能问题，同时扩展性也好。这里也会存在一个新的问题就是负载均衡，解决负载均衡的方法，当前CPU的调度队列定期窥探其他CPU上的任务数是否比自己还有满，如果不是则从其他的CPU上把任务迁移到当前CPU上的调度队列上，这个也叫工作窃取(work stealing)

- Linux 下有三种调度策略，具体如下
	- O(1)调度程序：这种调度程序是基于进程优先级，随着时间推移改变进程的优先级，然后调度最高优先级的进程，来实现各种调度目标
	- 完全公平调度(CFS):CFS是确定的比例调度方案。
	- BFS：采用单队列的算法，也是基于比例调度。